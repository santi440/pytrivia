{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de DataSets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento dataset n1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "from funciones import renombrar_prov\n",
    "\n",
    "path_read= Path ('../datasets/ar-airports.csv')\n",
    "path_write= Path ('../datasets_custom/ar-airports-custom.csv')\n",
    "path_read2= Path ('../datasets/ar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el import de la libreria csv, de la libreria unidecode y de la funcion Path de la liberaria pathlib. Se declara en variables diferentes los paths a los archivos que utilizaremos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectura = open (path_read, mode='r',encoding= 'UTF-8') \n",
    "lectura2 = open (path_read2, mode='r', encoding= 'UTF-8')\n",
    "escritura= open(path_write ,mode='w',encoding= 'UTF-8' ,newline= '') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se abre los archivos de lectura en modo lectura ('r') y el archivo de escritura en modo escritura ('w'). También se especifica la codificación (UTF-8) y se establece newline=' ' para manejar los saltos de línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectorcsv= csv.reader(lectura)\n",
    "lectorcsv2=csv.DictReader (lectura2)\n",
    "escritorcsv= csv.writer (escritura)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un lector CSV (lectorcsv) para leer el archivo de entrada de los aeropuertos, un lector CSV de tipo dict (lectorcsv2) para leer el archivo de entrada de las provincias y ciudades de manera mas facil y un escritor CSV (escritorcsv) para escribir en el archivo de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encabezado = next(lectorcsv)\n",
    "encabezado.append ('prov_name')\n",
    "encabezado.append ('elevation_name')\n",
    "escritorcsv.writerow (encabezado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee la primera fila del archivo de entrada para obtener el encabezado. Luego, se agregan las cadenas 'elevation_name' y 'prov_name' al encabezado. El encabezado actualizado se escribe en el archivo de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ciudad_prov= {}\n",
    "for line in lectorcsv2:\n",
    "    ciudad_prov [unidecode(line['city'])] = line ['admin_name']\n",
    "\n",
    "ciudad_prov ['Buenos Aires'] = 'Ciudad Autónoma de Buenos Aires' # Buenos Aires se hace a mano porque esta mal escrito en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recorro el dataset ar.csv y guardo en un diccionario el nombre de las ciudades y su respectiva provincia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fila in lectorcsv:\n",
    "    city = unidecode(fila[13])\n",
    "    aux= renombrar_prov.renombar_prov (fila[10]) #consultar la funcion \"renombrar_prov\"\n",
    "    prov = ciudad_prov.get(city, aux)  \n",
    "    if prov== 'Tierra del Fuego':\n",
    "        prov= 'Tierra del Fuego, Antártida e Islas del Atlántico Sur' # No encontramos forma mas eficiente de hacer este cambio para que las consultas \n",
    "    # de los datasets funcionen correctamente. El cambio del nombre de Tierra del Fuego para que sea homogeneo en todo el programa es necesaria para el \n",
    "    # correcto funcionamiento de las demas consultas. \n",
    "    fila.append(prov)\n",
    "\n",
    "    try: \n",
    "        elevacion = float(fila[6])\n",
    "        if elevacion <= 131:\n",
    "            elevation_name= 'bajo'\n",
    "        elif elevacion <=903:\n",
    "            elevation_name= 'medio'\n",
    "        else:   \n",
    "            elevation_name='alto'\n",
    "\n",
    "        fila.append(elevation_name)\n",
    "        escritorcsv.writerow(fila)\n",
    "\n",
    "    except ValueError: \n",
    "        fila.append ('Sin altura')\n",
    "        escritorcsv.writerow(fila)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada fila restante en el archivo de entrada se agrega el nombre de la provincia a la linea utilizando el diccionario previamente creado (se utiliza unidecode para evitar errores por tildes), dado que en el dataset ar.csv NO estan todas las ciudades de las provincias, si sucede que la ciudad del aeropuerto no esta en el diccionario, utilizo la provincia del mismo dataset de los aeropuertos en la columna 10 (invocando la funcion renombrar_prov que elimina la palabra 'province'). Posteriormente, se intenta convertir el valor en la sexta columna (la cual es la elevacion del aeropuerto) a un número flotante. Si la conversión es exitosa, se procede a determinar la categoría de elevación ('bajo', 'medio' o 'alto') y se agrega al archivo csv en la columna creada previamente. Si la conversión falla (porque la linea esta vacia o no es un numero), se captura la excepción ValueError y se agrega la cadena 'Sin altura' a la fila.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectura.close()\n",
    "lectura2.close()\n",
    "escritura.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cierre de archivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento dataset n2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo las rutas de los archivos que seran el origen de los datos conectivida y la carpeta en que se creara el nuevo archivo con los datos procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "conectividad = Path('..','datasets') / \"Conectividad_Internet.csv\"\n",
    "conectividad_modificado = Path('..','datasets_custom') / \"Conectividad_Internet.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo uso de la funcion \"create_modified_file()\" de modules/Conexiones_internet, se genera un nuevo archivo con una nueva columna \"posee_conectividad\" si todos los campos que especifican los distintos tipos son \"NO\" la misma tendra \"NO\", con que uno solo de los tipos sea \"SI\" la columna tomara el valor \"SI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones import Conectividad_internet as connectivity\n",
    "connectivity.create_modified_file(conectividad,conectividad_modificado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento dataset n3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se importan los módulos y la función con la que se va a trabajar. También se definen las constantes que indican los índices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pathlib\n",
    "\n",
    "from funciones.lagos_argentina import degrees_to_decimal\n",
    "\n",
    "SUPERFICIE = 2\n",
    "COORDENADAS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando PathLib se crean las rutas del CSV de lectura y del CSV de escritura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dataset = pathlib.Path('../datasets/lagos_arg.csv')\n",
    "write_dataset = pathlib.Path('../datasets_custom/lagos_arg_custom.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se abren ambos archivos, uno en modo lectura, otro en modo escritura. Se indica la codificación **UTF-8**. Se usa *newline=''* para evitar líneas vacías entre las filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = open(read_dataset, mode='r', encoding='UTF-8', newline='')\n",
    "write_file = open(write_dataset, mode='w', encoding='UTF-8', newline='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se crean los iterables **reader** y **writer** con los que se va a trabajar sobre los archivos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(read_file)\n",
    "writer = csv.writer(write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toma el *header* del archivo de lectura y se elimina de ésta la columna **COORDENADAS**, ya que va a estar dividida en dos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_header = next(reader)\n",
    "reader_header.pop (COORDENADAS);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acto seguido se crea una lista en la que cada elemento es el texto de cada columna nueva. Luego se escribe el *header* del nuevo CSV concatenando la lista del header del archivo original y la lista de los nuevos elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extras_header = ['Sup Tamaño', 'Latitud(GMS)', 'Longitud(GMS)', 'Latitud(GD)', 'Longitud(GD)']\n",
    "writer.writerow(reader_header + extras_header);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un **For** sobre el iterable se realiza el procesamiento del archivo linea por linea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Superficie:** En la variable *sup* se almacena el contenido de la columna *SUPERFICIE* del archivo. Al ser CSV el dato es leído como string, por esto mismo es que se realiza la conversión a entero con *int()*.\n",
    "\n",
    "Utilizando dicha variable se compara si el valor es chico/medio/grande y se agrega al final de la linea, en la columna de *Sup Tamaño*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Coordenadas:** El String de la columna **COORDENADAS** se divide utilizando *split* (con el espacio entre medio), y ambas partes se guardan en *coordinates*. \n",
    "\n",
    "Acto seguido se elimina el String de la columna **COORDENADAS** y se agregan al final los valores separados que están en la lista *coordinates*.\n",
    "\n",
    "Finalmente empleando la misma lista *coordinates*: Se agregan los valores al final de la línea pero en este caso llamando a la función *degrees_to_decimal*. Esta función toma como argumento el String de coordinadas en formato GMS(grados, minutos y segundos) y lo retorna en GD(grados decimales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in reader:\n",
    "    # Superficie\n",
    "    sup = int(line[SUPERFICIE])\n",
    "\n",
    "    if sup <= 17:\n",
    "        line.append ('chico')\n",
    "    elif sup <= 59:\n",
    "        line.append ('medio')\n",
    "    else:\n",
    "        line.append ('grande')\n",
    "\n",
    "    # Coordenadas\n",
    "    coordinates = line[COORDENADAS].split(' ')\n",
    "    line.pop(COORDENADAS)\n",
    "\n",
    "    line.append (coordinates[0]) \n",
    "    line.append (coordinates[1]) \n",
    "\n",
    "    line.append (degrees_to_decimal(coordinates[0]))\n",
    "    line.append (degrees_to_decimal(coordinates[1])) \n",
    "\n",
    "    writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar se cierran ambos archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file.close()\n",
    "write_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento dataset n4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo el módulo \"censo2022\" desde la carpeta \"funciones\" e invoco a la función \"create_modified_file\" para generar un nuevo archivo .csv en el directorio \"datasets_custom\" a partir de los datos existentes en el archivo \"c2022_tp_c_resumen_adaptado.csv\".\n",
    "Si ya existe el archivo modificado, lo sobreescribe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones import censo2022 as cd\n",
    "from pathlib import Path\n",
    "file_route = Path('..','datasets')/ 'c2022_tp_c_resumen_adaptado.csv'\n",
    "new_file_route = Path('..','datasets_custom')/ 'Censo_Modificado.csv'\n",
    "cd.create_modified_file(file_route,new_file_route)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
